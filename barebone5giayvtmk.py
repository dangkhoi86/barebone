import requests
from bs4 import BeautifulSoup
import re
import time
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime
import json
import urllib.parse
from gspread_formatting import format_cell_range, CellFormat, TextFormat, set_column_width, Color, Padding
from tenacity import retry, stop_after_attempt, wait_exponential
from concurrent.futures import ThreadPoolExecutor

SHEET_URL = "https://docs.google.com/spreadsheets/d/1N-aHLsVYKt9H_7xc4thFb1Ey6h2Mj7F93Ett_uEEMZQ/edit#gid=0"
SHEET_5GIAY_URL = SHEET_URL  # DÃ¹ng cÃ¹ng 1 link Google Sheet
today_str = datetime.now().strftime("%d-%m-%Y")
compare_sheet_name = f"Check-Gia-VTMK-{today_str}"

def get_all_barebone_links():
    base_url = "https://vitinhminhkhoi.vn/product-category/san-pham/barabone-may-bo/"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    product_links = dict()
    page = 1
    while True:
        url = base_url if page == 1 else f"{base_url}page/{page}/"
        print(f"Äang láº¥y link tá»«: {url}")
        resp = requests.get(url, headers=headers)
        if resp.status_code != 200:
            print("  -> Lá»–I: KhÃ´ng truy cáº­p Ä‘Æ°á»£c trang danh má»¥c nÃ y!")
            break
        soup = BeautifulSoup(resp.text, "html.parser")
        for a in soup.find_all('a', href=True):
            if '/product/' in a['href']:
                full_link = a['href'] if a['href'].startswith('http') else f"https://vitinhminhkhoi.vn{a['href']}"
                if full_link not in product_links:
                    product_links[full_link] = page
        next_btn = soup.find('a', class_='next page-numbers')
        if not next_btn:
            break
        page += 1
        time.sleep(1)
    # Tráº£ vá» list cÃ¡c tuple (link, page)
    return [(link, product_links[link]) for link in product_links]

def get_barebone_info(url, page):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        resp = requests.get(url, headers=headers, timeout=10)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        # Láº¥y tiÃªu Ä‘á» post
        post_title = ""
        h2 = soup.find('h2', class_='product-name')
        if h2:
            post_title = h2.text.strip()
        # Láº¥y báº£ng thÃ´ng tin
        table = soup.find('table', class_=['notcauhinh', 'cauhinh'])
        results = []
        if table:
            rows = table.find_all('tr')
            for row in rows[1:]:  # bá» header
                tds = row.find_all('td')
                if len(tds) > 1:
                    name = tds[0].text.strip()
                    # XÃ³a thÃ´ng tin trong dáº¥u ngoáº·c Ä‘Æ¡n
                    name = re.sub(r'\([^)]*\)', '', name).strip()
                    # ThÃªm "[Äang áº¨n]" náº¿u tr cÃ³ thuá»™c tÃ­nh hidden
                    if row.has_attr('hidden'):
                        name = f"{name} [Äang áº¨n]"
                    # Chá»‰ láº¥y dÃ²ng cÃ³ chá»¯ 'barebone' (khÃ´ng phÃ¢n biá»‡t hoa thÆ°á»ng)
                    if 'barebone' not in name.lower():
                        continue
                    price_text = tds[1].text
                    strong = tds[1].find('strong')
                    if strong:
                        price_text = strong.text
                    price = price_text.strip().replace('.', '').replace(',', '').replace('VND', '').replace('Ä‘', '')
                    try:
                        price = int(price)
                    except:
                        price = None
                    print(f"TÃªn: {name} | GiÃ¡: {price} | Link: {url} | Trang: {page}")
                    results.append({
                        "TÃªn Post": post_title,
                        "TÃªn sáº£n pháº©m": name,
                        "GiÃ¡ bÃ¡n (VNÄ)": price,
                        "Link": url,
                        "Trang": page
                    })
        else:
            print(f"KhÃ´ng tÃ¬m tháº¥y báº£ng thÃ´ng tin táº¡i {url}")
        return results
    except requests.exceptions.RequestException as e:
        print(f"Lá»—i khi truy cáº­p {url}: {str(e)}")
        return []

def upload_to_gsheets(df, sheet_url, worksheet_name="Sheet1"):
    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive"
    ]
    creds = ServiceAccountCredentials.from_json_keyfile_name('credentials.json', scope)
    client = gspread.authorize(creds)
    sh = client.open_by_url(sheet_url)
    try:
        worksheet = sh.worksheet(worksheet_name)
        worksheet.clear()
    except:
        worksheet = sh.add_worksheet(title=worksheet_name, rows="300", cols="7")
    # Thay tháº¿ NaN báº±ng None hoáº·c chuá»—i rá»—ng
    df = df.fillna("")  # Hoáº·c df = df.fillna(None)
    # Ghi header + data
    worksheet.update([df.columns.values.tolist()] + df.values.tolist())
    print(f"ÄÃ£ upload dá»¯ liá»‡u lÃªn Google Sheets: {worksheet_name}")

    # Sau khi Ä‘Ã£ upload dá»¯ liá»‡u lÃªn sheet vÃ  cÃ³ biáº¿n worksheet
    header_format = CellFormat(
        backgroundColor=Color(0.2, 0.6, 0.86),  # Xanh dÆ°Æ¡ng nháº¡t, Ä‘á»•i theo Ã½ báº¡n
        textFormat=TextFormat(bold=True, fontFamily='Arial', fontSize=11, foregroundColor=Color(1,1,1)),  # Chá»¯ tráº¯ng, in Ä‘áº­m
        padding=Padding(left=5, top=5, right=5, bottom=5)
    )
    format_cell_range(worksheet, 'A1:G1', header_format)

    number_format = CellFormat(
        numberFormat={'type': 'NUMBER', 'pattern': '#,##0'},
        horizontalAlignment='RIGHT'
    )

    format_cell_range(worksheet, 'C1:E1000', number_format)

    padding_format = CellFormat(
        padding=Padding(left=5, top=5, right=5, bottom=5)
    )
    format_cell_range(worksheet, 'A2:F1000', padding_format)

    set_column_width(worksheet, 'A', 300)
    set_column_width(worksheet, 'B', 400)
    set_column_width(worksheet, 'C', 111)
    set_column_width(worksheet, 'D', 111)
    set_column_width(worksheet, 'E', 91)
    set_column_width(worksheet, 'F', 200)
    set_column_width(worksheet, 'G', 200)

    left_middle_format = CellFormat(
        horizontalAlignment='LEFT',
        verticalAlignment='MIDDLE'
    )
    format_cell_range(worksheet, 'A1:A1000', left_middle_format)

    left_format = CellFormat(
        horizontalAlignment='LEFT',
    )
    format_cell_range(worksheet, 'B1:B1000', left_format)
    format_cell_range(worksheet, 'F1:G1000', left_format)

    middle_format = CellFormat(
        verticalAlignment='MIDDLE'
    )
    format_cell_range(worksheet, 'A1:G1000', middle_format)

    worksheet.freeze(rows=1)
    # worksheet.freeze(rows=1, cols=1)

def merge_link_cells(sheet_url, worksheet_name="Sheet1", link_col=3):
    # link_col: cá»™t Link, máº·c Ä‘á»‹nh lÃ  cá»™t thá»© 3 (A=1, B=2, C=3, ...)
    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive"
    ]
    creds = ServiceAccountCredentials.from_json_keyfile_name('credentials.json', scope)
    client = gspread.authorize(creds)
    sh = client.open_by_url(sheet_url)
    worksheet = sh.worksheet(worksheet_name)
    data = worksheet.get_all_values()
    last_link = None
    start_row = None
    for i, row in enumerate(data[1:], start=2):  # Bá» header, báº¯t Ä‘áº§u tá»« dÃ²ng 2
        link = row[link_col-1]
        if link == last_link:
            # Äang trong chuá»—i giá»‘ng nhau
            continue
        else:
            # Náº¿u cÃ³ chuá»—i trÆ°á»›c Ä‘Ã³ dÃ i hÆ¡n 1, thÃ¬ merge
            if start_row and i-1 > start_row:
                worksheet.merge_cells(
                    start_row, link_col, i-1, link_col
                )
            last_link = link
            start_row = i
    # Merge chuá»—i cuá»‘i cÃ¹ng náº¿u cáº§n
    if start_row and len(data) > start_row:
        worksheet.merge_cells(
            start_row, link_col, len(data), link_col
        )
    print("ÄÃ£ merge cÃ¡c Ã´ link giá»‘ng nhau.")

def merge_post_title_cells(sheet_url, worksheet_name="Sheet1", post_col=1):
    # post_col: cá»™t TÃªn Post, máº·c Ä‘á»‹nh lÃ  cá»™t Ä‘áº§u tiÃªn (A=1)
    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive"
    ]
    creds = ServiceAccountCredentials.from_json_keyfile_name('credentials.json', scope)
    client = gspread.authorize(creds)
    sh = client.open_by_url(sheet_url)
    worksheet = sh.worksheet(worksheet_name)
    data = worksheet.get_all_values()
    last_post = None
    start_row = None
    for i, row in enumerate(data[1:], start=2):  # Bá» header, báº¯t Ä‘áº§u tá»« dÃ²ng 2
        post = row[post_col-1]
        if post == last_post:
            continue
        else:
            if start_row and (i-1 - start_row + 1) >= 2:
                worksheet.merge_cells(
                    start_row, post_col, i-1, post_col
                )
            last_post = post
            start_row = i
    # Merge chuá»—i cuá»‘i cÃ¹ng náº¿u cáº§n
    if start_row and (len(data) - start_row + 1) >= 2:
        worksheet.merge_cells(
            start_row, post_col, len(data), post_col
        )
    print("ÄÃ£ merge cÃ¡c Ã´ TÃªn Post giá»‘ng nhau.")

def has_factor(part):
    # Kiá»ƒm tra part cÃ³ chá»©a 1 trong cÃ¡c factor khÃ´ng
    return bool(re.search(r'\b(sff|mt|dt|mini|tiny)\b', part, re.IGNORECASE))

def get_all_5giay_prices(sheet_url, sheet_date):
    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive"
    ]
    creds = ServiceAccountCredentials.from_json_keyfile_name('credentials.json', scope)
    client = gspread.authorize(creds)
    sh = client.open_by_url(sheet_url)
    worksheet = sh.worksheet(sheet_date)
    data = worksheet.get_all_records()
    
    # Táº¡o dictionary vá»›i key lÃ  tÃªn SP Ä‘Ã£ sá»­a vÃ  value lÃ  giÃ¡ bÃ¡n VC
    price_dict = {}
    for row in data:
        name_key = row.get("TÃªn SP Ä‘Ã£ sá»­a")
        if not name_key:
            continue
        name_key = name_key.lower().strip()
        price = row.get("GiÃ¡ bÃ¡n VC")
        price_dict[name_key] = price
    
    return price_dict

def get_price_from_5giay(name, price_dict):
    name = name.lower().strip()
    # So khá»›p trá»±c tiáº¿p vá»›i tÃªn SP Ä‘Ã£ sá»­a
    if name in price_dict:
        return price_dict[name]
    return "-"  # Tráº£ vá» "-" náº¿u khÃ´ng tÃ¬m tháº¥y tÃªn giá»‘ng nhau

def add_5giay_price_and_diff(df):
    # Äá»•i tÃªn cÃ¡c cá»™t trÆ°á»›c
    df = df.rename(columns={
        "TÃªn sáº£n pháº©m": "TÃªn SP VTMK",
        "GiÃ¡ bÃ¡n (VNÄ)": "GiÃ¡ VTMK"
    })

    prices_5giay = []
    diffs = []
    all_5giay_prices = get_all_5giay_prices(SHEET_5GIAY_URL, today_str)
    
    # In ra sá»‘ lÆ°á»£ng sáº£n pháº©m tÃ¬m tháº¥y giÃ¡
    found_prices = sum(1 for price in all_5giay_prices.values() if price is not None)
    print(f"TÃ¬m tháº¥y giÃ¡ cho {found_prices}/{len(all_5giay_prices)} sáº£n pháº©m")
    
    for idx, row in df.iterrows():
        product_name = row["TÃªn SP VTMK"].lower().strip()
        price_5giay = get_price_from_5giay(product_name, all_5giay_prices)
        prices_5giay.append(price_5giay)
        
        # TÃ­nh chÃªnh lá»‡ch chá»‰ khi cÃ³ giÃ¡ á»Ÿ cáº£ 2 bÃªn
        if price_5giay != "-" and row["GiÃ¡ VTMK"] is not None:
            try:
                diff = row["GiÃ¡ VTMK"] - int(price_5giay)
                # Náº¿u chÃªnh lá»‡ch = 0 thÃ¬ gÃ¡n "-"
                if diff == 0:
                    diff = "-"
            except:
                diff = ""
        else:
            diff = ""
        diffs.append(diff)
    
    # XÃ³a cá»™t Trang
    df = df.drop(columns=["Trang"])
    
    # ThÃªm cá»™t GiÃ¡ 5giay vÃ  ChÃªnh lá»‡ch
    cols = list(df.columns)
    price_col_idx = cols.index("GiÃ¡ VTMK")
    df.insert(price_col_idx + 1, "GiÃ¡ 5giay", prices_5giay)
    df.insert(price_col_idx + 2, "ChÃªnh lá»‡ch", diffs)
    
    # ThÃªm link vÃ  cÃ¡c cá»™t khÃ¡c
    df["Link"] = df.apply(lambda row: make_text_fragment_link(row["Link"], row["TÃªn SP VTMK"]), axis=1)
    
    cols = df.columns.tolist()
    cols = ['TÃªn Post'] + [col for col in cols if col != 'TÃªn Post']
    df = df[cols]
    
    return df

def chuan_hoa_ten(name):
    return re.sub(r'\s*([\\/|])\s*', r'\1', name.strip().lower())

def extract_model_part(name):
    # Chuyá»ƒn vá» chá»¯ thÆ°á»ng Ä‘á»ƒ dá»… xá»­ lÃ½
    name = name.lower()
    # Loáº¡i bá» tiá»n tá»‘ "barebone" vÃ  hÃ£ng náº¿u cÃ³
    # VÃ­ dá»¥: "barebone dell 400g1 sff" -> "400g1 sff"
    match = re.search(r'barebone\s+(dell|hp|lenovo)?\s*(.*)', name)
    if match:
        return match.group(2).strip()
    return name.strip()

def make_text_fragment_link(base_url, product_name):
    encoded_text = urllib.parse.quote(product_name)
    return f"{base_url}#:~:text={encoded_text}"

def add_arrow_to_price(row):
    diff = row["ChÃªnh lá»‡ch"]
    price = row["GiÃ¡ VTMK"]
    if diff == "" or price == "":
        return price
    try:
        diff_val = int(diff)
        if diff_val == 0:
            return f"{price:,}"
        elif diff_val < 0:
            arrow = "ðŸ”º"  # MÅ©i tÃªn lÃªn
        else:
            arrow = "ðŸ”»"  # MÅ©i tÃªn xuá»‘ng
        return f"{arrow} {price:,}"
    except:
        return price

def clear_duplicate_post_title(df):
    # Náº¿u "TÃªn Post" giá»‘ng dÃ²ng trÆ°á»›c thÃ¬ Ä‘á»ƒ trá»‘ng
    df = df.copy()
    df['TÃªn Post'] = df['TÃªn Post'].where(df['TÃªn Post'].ne(df['TÃªn Post'].shift()))
    return df

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
def get_post_id_from_shortlink(product_url):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        resp = requests.get(product_url, headers=headers, timeout=5)  # Giáº£m timeout xuá»‘ng 5s
        if resp.status_code != 200:
            return ""
        soup = BeautifulSoup(resp.text, "html.parser")
        shortlink_tag = soup.find("link", rel="shortlink")
        if shortlink_tag and "href" in shortlink_tag.attrs:
            match = re.search(r"p=(\d+)", shortlink_tag["href"])
            if match:
                return match.group(1)
        return ""
    except Exception as e:
        print(f"Lá»—i khi láº¥y post ID tá»« {product_url}: {str(e)}")
        return ""

def add_post_id_column(df):
    # Giáº£ sá»­ cá»™t "Link" chá»©a link sáº£n pháº©m
    ids = []
    for url in df["Link"]:
        post_id = get_post_id_from_shortlink(url)
        ids.append(post_id)
    # ThÃªm cá»™t "ID" sau cá»™t "ChÃªnh lá»‡ch"
    insert_idx = df.columns.get_loc("ChÃªnh lá»‡ch") + 1
    df.insert(insert_idx, "ID", ids)
    return df

def add_edit_price_column(df):
    # Láº¥y ID tá»« cá»™t "ID" vÃ  táº¡o link sá»­a (KHÃ”NG thÃªm text fragment)
    edit_links = []
    for post_id in df["ID"]:
        if post_id:
            edit_link = f"https://vitinhminhkhoi.vn/wp-admin/post.php?post={post_id}&action=edit"
        else:
            edit_link = ""
        edit_links.append(edit_link)
    # ThÃªm cá»™t "Sá»­a GiÃ¡" sau cá»™t "Link"
    insert_idx = df.columns.get_loc("Link") + 1
    df.insert(insert_idx, "Sá»­a GiÃ¡", edit_links)
    # XÃ³a cá»™t "ID"
    df = df.drop(columns=["ID"])
    return df

if __name__ == "__main__":
    all_links = get_all_barebone_links()
    print(f"Tá»•ng sá»‘ link sáº£n pháº©m: {len(all_links)}")
    all_products = []
    for idx, (link, page) in enumerate(all_links, 1):
        print(f"({idx}/{len(all_links)}) Äang láº¥y: {link} (Trang {page})")
        infos = get_barebone_info(link, page)
        all_products.extend(infos)
        time.sleep(1)
    # Chuyá»ƒn sang DataFrame
    df = pd.DataFrame(all_products)
    # Upload lÃªn Google Sheets
    df = add_5giay_price_and_diff(df)
    df["GiÃ¡ VTMK"] = df.apply(add_arrow_to_price, axis=1)
    df = clear_duplicate_post_title(df)
    df = df.loc[df['TÃªn Post'].ne(df['TÃªn Post'].shift())].reset_index(drop=True)
    total = df['TÃªn Post'].replace('', pd.NA).dropna().shape[0]
    df = df.rename(columns={"TÃªn Post": f"TÃªn Post [{total}]"})
    # ThÃªm post ID vÃ  link sá»­a
    df = add_post_id_column(df)
    df = add_edit_price_column(df)
    upload_to_gsheets(df, SHEET_URL, worksheet_name=compare_sheet_name)
