import requests
from bs4 import BeautifulSoup
import re
import time
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime
import json
import urllib.parse
from gspread_formatting import format_cell_range, CellFormat, TextFormat, set_column_width, Color, Padding
from tenacity import retry, stop_after_attempt, wait_exponential
import os
SHEET_URL = os.environ.get("SHEET_URL")
WC_API_URL = os.environ.get("MK_WC_API_URL")
WC_CONSUMER_KEY = os.environ.get("MK_WC_CONSUMER_KEY")
WC_CONSUMER_SECRET = "os.environ.get("MK_WC_CONSUMER_SECRET")
SHEET_5GIAY_URL = SHEET_URL

today_str = datetime.now().strftime("%d-%m-%Y")
compare_sheet_name = f"Check-Gia-MKCOM-{today_str}"

def get_all_barebone_products():
    """L·∫•y t·∫•t c·∫£ s·∫£n ph·∫©m barebone th√¥ng qua WooCommerce API"""
    products = [] # This will accumulate all rows for the DataFrame
    page = 1
    per_page = 100
    
    while True:
        url = f"{WC_API_URL}/products"
        params = {
            'consumer_key': WC_CONSUMER_KEY,
            'consumer_secret': WC_CONSUMER_SECRET,
            'per_page': per_page,
            'page': page,
            'search': 'barebone'
        }
        
        try:
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()
            
            if not data:
                break
                
            for product_api_data in data: # Renamed to avoid conflict with product variable in inner loop
                post_title = product_api_data.get('name', '')
                product_link = product_api_data.get('permalink', '')
                status = product_api_data.get('status', '')
                modified_by = product_api_data.get('modified_by', '')
                description = product_api_data.get('description', '')
                
                status_icon = "-"
                if status == 'publish':
                    status_icon = 'üëÄ'
                elif status == 'pending':
                    status_icon = '‚è∞'
                elif status == 'private':
                    status_icon = 'üîí'
                elif status == 'draft':
                    status_icon = 'üìù'

                # Bi·∫øn c·ªù ƒë·ªÉ ki·ªÉm tra xem c√≥ s·∫£n ph·∫©m barebone n√†o ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ b·∫£ng kh√¥ng
                has_extracted_from_table = False
                
                if description:
                    desc_soup = BeautifulSoup(description, "html.parser")
                    # T√¨m t·∫•t c·∫£ c√°c b·∫£ng 'notcauhinh' ho·∫∑c 'cauhinh'
                    tables = desc_soup.find_all('table', class_=['notcauhinh', 'cauhinh'])
                    
                    if tables:
                        for table in tables:
                            rows_in_table = table.find_all('tr')
                            
                            for row_idx, row in enumerate(rows_in_table):
                                # B·ªè qua h√†ng ti√™u ƒë·ªÅ n·∫øu c√≥ (ki·ªÉm tra <th> ho·∫∑c n·∫øu l√† h√†ng ƒë·∫ßu ti√™n v√† kh√¥ng c√≥ <td>)
                                if row.find('th') or (row_idx == 0 and not row.find_all('td')):
                                    continue 

                                tds = row.find_all('td')
                                if len(tds) > 1: # ƒê·∫£m b·∫£o c√≥ ƒë·ªß c·ªôt cho t√™n v√† gi√°
                                    name_from_table = tds[0].text.strip()
                                    
                                    # X√≥a th√¥ng tin trong d·∫•u ngo·∫∑c ƒë∆°n
                                    name_from_table = re.sub(r'\([^)]*\)', '', name_from_table).strip()
                                    
                                    # Ch·ªâ l·∫•y d√≤ng c√≥ ch·ªØ 'barebone' (kh√¥ng ph√¢n bi·ªát hoa th∆∞·ªùng)
                                    if 'barebone' not in name_from_table.lower():
                                        continue 
                                    
                                    # L·∫•y gi√° t·ª´ b·∫£ng (c·ªôt th·ª© 2)
                                    price_from_table = None
                                    price_text = tds[1].text
                                    strong_tag = tds[1].find('strong')
                                    if strong_tag:
                                        price_text = strong_tag.text
                                    price_text = price_text.strip().replace('.', '').replace(',', '').replace('VND', '').replace('ƒë', '')
                                    try:
                                        price_from_table = int(price_text)
                                    except ValueError:
                                        price_from_table = None

                                    # X√°c ƒë·ªãnh "S·∫£n ph·∫©m ·∫©n" t·ª´ h√†ng hi·ªán t·∫°i
                                    current_row_is_hidden = "ƒêang ·∫©n" if 'admin-only' in row.get('class', []) else ""

                                    # √Åp d·ª•ng logic x√≥a "Precision" v√† chu·∫©n h√≥a kho·∫£ng tr·∫Øng cho t√™n s·∫£n ph·∫©m t·ª´ b·∫£ng
                                    cleaned_product_name_mkcom = re.sub(r'\bPrecision\b', '', name_from_table, flags=re.IGNORECASE)
                                    cleaned_product_name_mkcom = re.sub(r'\s+', ' ', cleaned_product_name_mkcom).strip()

                                    products.append({
                                        "T√™n Post": post_title,
                                        "T√™n s·∫£n ph·∫©m": cleaned_product_name_mkcom,
                                        "Gi√° b√°n (VNƒê)": price_from_table,
                                        "Link": product_link,
                                        "Trang": page,
                                        "T√¨nh tr·∫°ng": status_icon,
                                        "Ng∆∞·ªùi s·ª≠a": modified_by,
                                        "S·∫£n ph·∫©m ·∫©n": current_row_is_hidden
                                    })
                                    has_extracted_from_table = True # ƒê√£ tr√≠ch xu·∫•t √≠t nh·∫•t m·ªôt m·ª•c t·ª´ b·∫£ng
                
                # N·∫øu kh√¥ng c√≥ s·∫£n ph·∫©m barebone n√†o ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª´ b·∫£ng, ho·∫∑c kh√¥ng t√¨m th·∫•y b·∫£ng n√†o,
                # th√¨ th√™m th√¥ng tin s·∫£n ph·∫©m ch√≠nh (t·ª´ API)
                if not has_extracted_from_table and 'barebone' in post_title.lower():
                    # L·∫•y gi√° s·∫£n ph·∫©m ch√≠nh t·ª´ API n·∫øu kh√¥ng c√≥ gi√° c·ª• th·ªÉ t·ª´ b·∫£ng
                    main_product_price = product_api_data.get('price')
                    try:
                        main_product_price = int(float(main_product_price)) if main_product_price else None
                    except:
                        main_product_price = None

                    # √Åp d·ª•ng l√†m s·∫°ch cho t√™n b√†i ƒëƒÉng g·ªëc n·∫øu ƒë√≥ l√† barebone v√† kh√¥ng t√¨m th·∫•y m·ª•c n√†o trong b·∫£ng
                    cleaned_post_title_mkcom = re.sub(r'\bPrecision\b', '', post_title, flags=re.IGNORECASE)
                    cleaned_post_title_mkcom = re.sub(r'\s+', ' ', cleaned_post_title_mkcom).strip()

                    products.append({
                        "T√™n Post": post_title,
                        "T√™n s·∫£n ph·∫©m": cleaned_post_title_mkcom, # T√™n SP MKCOM s·∫Ω l√† t√™n post n·∫øu kh√¥ng c√≥ b·∫£ng
                        "Gi√° b√°n (VNƒê)": main_product_price,
                        "Link": product_link,
                        "Trang": page,
                        "T√¨nh tr·∫°ng": status_icon,
                        "Ng∆∞·ªùi s·ª≠a": modified_by,
                        "S·∫£n ph·∫©m ·∫©n": "" # Kh√¥ng ·∫©n n·∫øu kh√¥ng ph·∫£i t·ª´ h√†ng admin-only c·ªßa b·∫£ng
                    })

            page += 1
            time.sleep(1)
            
        except requests.exceptions.RequestException as e:
            print(f"L·ªói khi l·∫•y d·ªØ li·ªáu t·ª´ API: {str(e)}")
            break
            
    return products

def upload_to_gsheets(df, sheet_url, worksheet_name="Sheet1"):
    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive"
    ]
    creds = ServiceAccountCredentials.from_json_keyfile_name('credentials.json', scope)
    client = gspread.authorize(creds)
    sh = client.open_by_url(sheet_url)
    try:
        worksheet = sh.worksheet(worksheet_name)
        worksheet.clear()
    except:
        worksheet = sh.add_worksheet(title=worksheet_name, rows="300", cols="10")
    # Thay th·∫ø NaN b·∫±ng None ho·∫∑c chu·ªói r·ªóng
    df = df.fillna("")  # Ho·∫∑c df = df.fillna(None)
    # Ghi header + data
    worksheet.update([df.columns.values.tolist()] + df.values.tolist())
    print(f"ƒê√£ upload d·ªØ li·ªáu l√™n Google Sheets: {worksheet_name}")

    # Sau khi ƒë√£ upload d·ªØ li·ªáu l√™n sheet v√† c√≥ bi·∫øn worksheet
    header_format = CellFormat(
        backgroundColor=Color(0.2, 0.6, 0.86),  # Xanh d∆∞∆°ng nh·∫°t, ƒë·ªïi theo √Ω b·∫°n
        textFormat=TextFormat(bold=True, fontFamily='Arial', fontSize=11, foregroundColor=Color(1,1,1)),  # Ch·ªØ tr·∫Øng, in ƒë·∫≠m
        padding=Padding(left=5, top=5, right=5, bottom=5)
    )
    format_cell_range(worksheet, 'A1:J1', header_format)

    number_format = CellFormat(
        numberFormat={'type': 'NUMBER', 'pattern': '#,##0'},
        horizontalAlignment='RIGHT'
    )

    format_cell_range(worksheet, 'C1:E1000', number_format)

    padding_format = CellFormat(
        padding=Padding(left=5, top=5, right=5, bottom=5)
    )
    format_cell_range(worksheet, 'A2:J1000', padding_format)

    left_middle_format = CellFormat(
        horizontalAlignment='LEFT',
        verticalAlignment='MIDDLE'
    )
    format_cell_range(worksheet, 'A1:A1000', left_middle_format)

    left_format = CellFormat(
        horizontalAlignment='LEFT',
    )
    format_cell_range(worksheet, 'B1:B1000', left_format)
    format_cell_range(worksheet, 'F1:G1000', left_format)
    format_cell_range(worksheet, 'J1:J1000', left_format)

    center_format = CellFormat(
        horizontalAlignment='CENTER',
    )
    format_cell_range(worksheet, 'H1:I1000', center_format)

    middle_format = CellFormat(
        verticalAlignment='MIDDLE'
    )
    format_cell_range(worksheet, 'A1:J1000', middle_format)

    worksheet.freeze(rows=1)

    # ƒêi·ªÅu ch·ªânh ƒë·ªô r·ªông c·ªôt (T·ªïng c·ªông 10 c·ªôt)
    set_column_width(worksheet, 'A', 300)
    set_column_width(worksheet, 'B', 400)
    set_column_width(worksheet, 'C', 111)
    set_column_width(worksheet, 'D', 111)
    set_column_width(worksheet, 'E', 91)
    set_column_width(worksheet, 'F', 200)
    set_column_width(worksheet, 'G', 200)
    set_column_width(worksheet, 'H', 90)
    set_column_width(worksheet, 'I', 100)
    set_column_width(worksheet, 'J', 90)

    return worksheet

def merge_link_cells(sheet_url, worksheet_name="Sheet1", link_col=3):
    # link_col: c·ªôt Link, m·∫∑c ƒë·ªãnh l√† c·ªôt th·ª© 3 (A=1, B=2, C=3, ...)
    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive"
    ]
    creds = ServiceAccountCredentials.from_json_keyfile_name('credentials.json', scope)
    client = gspread.authorize(creds)
    sh = client.open_by_url(sheet_url)
    worksheet = sh.worksheet(worksheet_name)
    data = worksheet.get_all_values()
    last_link = None
    start_row = None
    for i, row in enumerate(data[1:], start=2):  # B·ªè header, b·∫Øt ƒë·∫ßu t·ª´ d√≤ng 2
        link = row[link_col-1]
        if link == last_link:
            # ƒêang trong chu·ªói gi·ªëng nhau
            continue
        else:
            # N·∫øu c√≥ chu·ªói tr∆∞·ªõc ƒë√≥ d√†i h∆°n 1, th√¨ merge
            if start_row and i-1 > start_row:
                worksheet.merge_cells(
                    start_row, link_col, i-1, link_col
                )
            last_link = link
            start_row = i
    # Merge chu·ªói cu·ªëi c√πng n·∫øu c·∫ßn
    if start_row and len(data) > start_row:
        worksheet.merge_cells(
            start_row, link_col, len(data), link_col
        )
    print("ƒê√£ merge c√°c √¥ link gi·ªëng nhau.")

def has_factor(part):
    # Ki·ªÉm tra part c√≥ ch·ª©a 1 trong c√°c factor kh√¥ng
    return bool(re.search(r'\b(sff|mt|dt|mini|tiny)\b', part, re.IGNORECASE))

def get_all_5giay_prices(sheet_url, sheet_date):
    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive"
    ]
    creds = ServiceAccountCredentials.from_json_keyfile_name('credentials.json', scope)
    client = gspread.authorize(creds)
    sh = client.open_by_url(sheet_url)
    worksheet = sh.worksheet(sheet_date)
    data = worksheet.get_all_records()
    
    # In ra t√™n c√°c c·ªôt ƒë·ªÉ ki·ªÉm tra
    print("C√°c c·ªôt trong sheet:", list(data[0].keys()) if data else "Kh√¥ng c√≥ d·ªØ li·ªáu")
    
    # Th·ª≠ l·∫•y gi√° t·ª´ c√°c c·ªôt c√≥ th·ªÉ ch·ª©a gi√°
    price_dict = {}
    for row in data:
        name_key = row.get("T√™n SP ƒë√£ s·ª≠a") or row.get("T√™n s·∫£n ph·∫©m")
        if not name_key:
            continue
        name_key = name_key.lower().strip()
        price = None
        if "Gi√° b√°n VC" in row:
            price = row["Gi√° b√°n VC"]
        elif "Gi√° b√°n (VNƒê)" in row:
            price = row["Gi√° b√°n (VNƒê)"]
        elif "Gi√°" in row:
            price = row["Gi√°"]
        # L∆∞u c·∫£ chu·ªói g·ªëc l√†m key
        price_dict[name_key] = price

        # Split theo / n·∫øu t·∫•t c·∫£ c√°c ph·∫ßn ƒë·ªÅu c√≥ factor
        parts = [p.strip() for p in name_key.split('/')]
        if len(parts) > 1 and all(has_factor(p) for p in parts):
            for part in parts:
                price_dict[part] = price
    
    return price_dict

def add_5giay_price_and_diff(df):
    # ƒê·ªïi t√™n c√°c c·ªôt tr∆∞·ªõc
    df = df.rename(columns={
        "T√™n s·∫£n ph·∫©m": "T√™n SP MKCOM",
        "Gi√° b√°n (VNƒê)": "Gi√° MKCOM"
    })

    prices_5giay = []
    diffs = []
    all_5giay_prices = get_all_5giay_prices(SHEET_5GIAY_URL, today_str)
    
    # In ra s·ªë l∆∞·ª£ng s·∫£n ph·∫©m t√¨m th·∫•y gi√°
    found_prices = sum(1 for price in all_5giay_prices.values() if price is not None)
    print(f"T√¨m th·∫•y gi√° cho {found_prices}/{len(all_5giay_prices)} s·∫£n ph·∫©m")
    
    for idx, row in df.iterrows():
        product_name = row["T√™n SP MKCOM"].lower().strip()
        price_5giay = get_price_from_5giay(product_name, all_5giay_prices)
        prices_5giay.append(price_5giay)
        
        # T√≠nh ch√™nh l·ªách ch·ªâ khi c√≥ gi√° ·ªü c·∫£ 2 b√™n
        if price_5giay != "-" and row["Gi√° MKCOM"] is not None:
            try:
                diff = row["Gi√° MKCOM"] - int(price_5giay)
                # N·∫øu ch√™nh l·ªách = 0 th√¨ g√°n "-"
                if diff == 0:
                    diff = "-"
            except:
                diff = ""
        else:
            diff = ""
        diffs.append(diff)
    
    # X√≥a c·ªôt Trang
    df = df.drop(columns=["Trang"])
    
    # Th√™m c·ªôt Gi√° 5giay v√† Ch√™nh l·ªách
    cols = list(df.columns)
    price_col_idx = cols.index("Gi√° MKCOM")
    df.insert(price_col_idx + 1, "Gi√° 5giay", prices_5giay)
    df.insert(price_col_idx + 2, "Ch√™nh l·ªách", diffs)
    
    # Th√™m link v√† c√°c c·ªôt kh√°c
    df["Link"] = df.apply(lambda row: make_text_fragment_link(row["Link"], row["T√™n SP MKCOM"]), axis=1)
    
    cols = df.columns.tolist()
    cols = ['T√™n Post'] + [col for col in cols if col != 'T√™n Post']
    df = df[cols]
    
    return df

def chuan_hoa_ten(name):
    return re.sub(r'\s*([\\/|])\s*', r'\1', name.strip().lower())

def extract_model_part(name):
    # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng ƒë·ªÉ d·ªÖ x·ª≠ l√Ω
    name = name.lower()
    # Lo·∫°i b·ªè ti·ªÅn t·ªë "barebone" v√† h√£ng n·∫øu c√≥
    # V√≠ d·ª•: "barebone dell 400g1 sff" -> "400g1 sff"
    match = re.search(r'barebone\s+(dell|hp|lenovo)?\s*(.*)', name)
    if match:
        return match.group(2).strip()
    return name.strip()

def get_price_from_5giay(name, price_dict):
    name = name.lower().strip()
    # So kh·ªõp tr·ª±c ti·∫øp v·ªõi t√™n SP ƒë√£ s·ª≠a
    if name in price_dict:
        return price_dict[name]
    return "-"  # Tr·∫£ v·ªÅ "-" n·∫øu kh√¥ng t√¨m th·∫•y t√™n gi·ªëng nhau

def make_text_fragment_link(base_url, product_name):
    encoded_text = urllib.parse.quote(product_name)
    return f"{base_url}#:~:text={encoded_text}"

def add_arrow_to_price(row):
    diff = row["Ch√™nh l·ªách"]
    price = row["Gi√° MKCOM"]
    if diff == "" or price == "":
        return price
    try:
        diff_val = int(diff)
        if diff_val == 0:
            return f"{price:,}"
        elif diff_val < 0:
            arrow = "üî∫"  # M≈©i t√™n l√™n
        else:
            arrow = "üîª"  # M≈©i t√™n xu·ªëng
        return f"{arrow} {price:,}"
    except:
        return price

def clear_duplicate_post_title(df):
    df = df.copy()
    df['T√™n Post'] = df['T√™n Post'].where(df['T√™n Post'].ne(df['T√™n Post'].shift()))
    return df

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
def get_post_id_from_shortlink(product_url):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        resp = requests.get(product_url, headers=headers, timeout=5)  # Gi·∫£m timeout xu·ªëng 5s
        if resp.status_code != 200:
            return ""
        soup = BeautifulSoup(resp.text, "html.parser")
        shortlink_tag = soup.find("link", rel="shortlink")
        if shortlink_tag and "href" in shortlink_tag.attrs:
            match = re.search(r"p=(\d+)", shortlink_tag["href"])
            if match:
                return match.group(1)
        return ""
    except Exception as e:
        print(f"L·ªói khi l·∫•y post ID t·ª´ {product_url}: {str(e)}")
        return ""

def add_post_id_column(df):
    # Gi·∫£ s·ª≠ c·ªôt "Link" ch·ª©a link s·∫£n ph·∫©m
    ids = []
    for url in df["Link"]:
        post_id = get_post_id_from_shortlink(url)
        ids.append(post_id)
    # Th√™m c·ªôt "ID" sau c·ªôt "Ch√™nh l·ªách"
    insert_idx = df.columns.get_loc("Ch√™nh l·ªách") + 1
    df.insert(insert_idx, "ID", ids)
    return df

def add_edit_price_column(df):
    # L·∫•y ID t·ª´ c·ªôt "ID" v√† t·∫°o link s·ª≠a (KH√îNG th√™m text fragment)
    edit_links = []
    for post_id in df["ID"]:
        if post_id:
            edit_link = f"https://minhkhoicomputer.com/wp-admin/post.php?post={post_id}&action=edit"
        else:
            edit_link = ""
        edit_links.append(edit_link)
    # Th√™m c·ªôt "S·ª≠a Gi√°" sau c·ªôt "Link"
    insert_idx = df.columns.get_loc("Link") + 1
    df.insert(insert_idx, "S·ª≠a Gi√°", edit_links)
    # X√≥a c·ªôt "ID"
    df = df.drop(columns=["ID"])
    return df

if __name__ == "__main__":
    # L·∫•y t·∫•t c·∫£ s·∫£n ph·∫©m barebone
    all_products = get_all_barebone_products()
    print(f"T·ªïng s·ªë s·∫£n ph·∫©m barebone: {len(all_products)}")
    
    # Chuy·ªÉn sang DataFrame
    df = pd.DataFrame(all_products)
    
    # TH√äM ƒêO·∫†N CODE N√ÄY: B·ªè t·ª´ "Precision" v√† lo·∫°i b·ªè t·∫•t c·∫£ kho·∫£ng tr·∫Øng d∆∞ th·ª´a (ƒë·∫ßu, cu·ªëi, gi·ªØa c√°c t·ª´).
    # S·ª≠ d·ª•ng re.sub ƒë·ªÉ thay th·∫ø t·ª´ "Precision" v√† chu·∫©n h√≥a kho·∫£ng tr·∫Øng.
    # regex=True kh√¥ng c·∫ßn thi·∫øt khi d√πng .apply(lambda x: re.sub(...))
    df['T√™n s·∫£n ph·∫©m'] = df['T√™n s·∫£n ph·∫©m'].apply(lambda x: re.sub(r'\bPrecision\b', '', x, flags=re.IGNORECASE))
    df['T√™n s·∫£n ph·∫©m'] = df['T√™n s·∫£n ph·∫©m'].apply(lambda x: re.sub(r'\s+', ' ', x).strip())
    
    # X·ª≠ l√Ω v√† upload l√™n Google Sheets
    df = add_5giay_price_and_diff(df)
    df["Gi√° MKCOM"] = df.apply(add_arrow_to_price, axis=1)
    df = clear_duplicate_post_title(df)
    df = df.loc[df['T√™n Post'].ne(df['T√™n Post'].shift())].reset_index(drop=True)
    total = df['T√™n Post'].replace('', pd.NA).dropna().shape[0]
    df = df.rename(columns={"T√™n Post": f"T√™n Post [{total}]"})
    
    # Th√™m post ID v√† link s·ª≠a
    df = add_post_id_column(df)
    df = add_edit_price_column(df)
    
    # Upload l√™n Google Sheets
    upload_to_gsheets(df, SHEET_URL, worksheet_name=compare_sheet_name)
